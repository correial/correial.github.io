[{"url":"https://correial.github.io/","title":"About Me","description":null,"body":"\n  Lucca Correia\n  \n    \n      \n    \n  \n  \n    \n      \n    \n  \n\n\n\n\n\n \nJunior at Cornell University studying Mechanical Engineering with a focus in Robotics\nHere on campus I am on the Cornell Nexus Project Team as well as the Cornell United Soccer Club Team. I will be updating my site through the semester to reflect my progress in Fast Robots - MAE4190/ECE4160.\n","path":null},{"url":"https://correial.github.io/docs/","title":"Empty for now","description":null,"body":"\n","path":null},{"url":"https://correial.github.io/nexus/","title":"Empty for now","description":null,"body":"","path":null},{"url":"https://correial.github.io/Fast Robots/","title":"MAE 4190 Fast Robots Labs","description":null,"body":"","path":null},{"url":"https://correial.github.io/Fast Robots/lab-8/","title":"Lab 8: Stunts","description":null,"body":"\nCars 3 Way Tie\nFlip Implementation\nBluetooth Data Transmission\nThe entire flip program starts when called over bluetooth via the Jupyter notebook line: ble.send_command(CMD.STUNT, \"1200\"). The parameter passed in is the distance away from the wall that the car should begin to reverse at. Note that 1200 mm is larger than the distance away from the wall of the mat (300 mm) as the car needs time to slow down before ultimately flipping on the mat. This parameter allows for easy flip tuning for various different starting positions and flip locations.\nArduino Code\nThe STUNT command is responsible for ensuring the first kalman filter value is stored and  calling the essential Flip() and sendStuntData() functions. Here is the command:\n\nThe functions to note are:\n\nFlip()runs the logic to drive at the wall then flip the robot. While the robot has yet to reach the flip distance, it drives forward at full speed. Once it reaches the target distance, it runs in reverse at full speed for 2300 ms. Note that during both loops, ToF and Kalman data is being collected.\n\n\n\ncollectTOF() responsible for collecting current ToF values and updating the global TOF1 array with distances\ngetKalmanData() reads in the current TOF1 array value (updated by the collectTOF() function). In return it updates the global kf array with the kalman filter calculated distance which is used for tracking distance to the wall for the stunt. In the below code, you can see the use of an update flag that flips based on whether new sensor data is ready– this helps to speed up the process. The following A and B matrices were used post tuning:\n\n\n\n\n\n\nsendStuntData() loops through crucial arrays and sends them over bluetooth to be processed by the notification hanlder and piped into a csv for graphing and post prosessing.\n\nResults\nStunt Videos\nThe time elapsed for each stunt trial are in the image captions; the timer starts once the car passes the blue line and ends once it retuns and crosses it.\n\nFlip Trial 1 | Time: 2.38s\n\nFlip Trial 2 | Time: 2.36s\n\nFlip Trial 3 | Time: 2.30s\nGraphs for Trial 3\nFrom the graph you can see Kalman Filter Position vs. Time as well as Speed vs. Time. Note that the speed flips from 255 to -255 once the robots hits the target distance of 1200 mm. This distance was played around with until finally deciding that 1200 mm was just enough to have the robot flip on the mat (300 mm from the wall) without hitting the wall or flipping too early. You can see that the Kalman filter could use some further tuning as the model predicts too slow of a velocity (as seen from the lack of steepness in the bunched up data). Returning to the state space model, this could be improved by reducing m (to increase the B matrix) or increasing U (less intuitive fix). ToF sensor data is visible from the KF jumps but aren’t shown to reduce graph clutter.\n\nTrial 3 Graph\nBlooper Video\nHere is my blooper video! (Here is the original but vote on the edited cars version)\n\nBlooper\nSummary and Challenges\n\nYou can see that in two of the trials, an added weight is mounted to the front of the robot to help it nosedive and flip about its front. By the end I realized that the added mass did not help as much as a fully charged battery thus you can see that the trials with the added weight (1 and 2) are nearly identical to those without. The weight was made out of taped together washers and was shared between Trevor and I.\n\n\nRobot with (right) and without (left) weight\n\nThroughout the hours of testing, I had to use correction factors to straighted the car’s trajectory toward the mat and also help to slow the wheels down at the same time, ensuring that when flipped, the robot was oriented straight. My correction terms scale the passed in PWM speed. When driving at the wall, a correction term of 0.95 scales the right side motor and when driving in reverse (slowing down) a correction factor of 0.90 scales the left side motor. The blooper is an example of the robot before tuning. You can see it arc left when approaching the wall and then spinning as it slowed down which made it ultimately return at the completely wrong angle.\n\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. ChatGPT was used to help plot graphs.\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-7/","title":"Lab 7: Kalman Filter","description":null,"body":"Drag and Mass Estimations\nWe can start with approximating the open-loop robot system as first-order using Newton’s second law\n$$ F = ma = m\\ddot{x} $$\nthen adding the linear drag force (d) and motor input (u),\n$$ F = -d\\dot{x} + u $$\nthe dynamics of the system can be described in terms of second derivative of position\n$$ \\ddot{x} = -\\frac{d}{m} \\dot{x} + \\frac{u}{m} $$\nThen, we can represent the system in state space notation with the state vector\n\n\nThe corresponding dynamics in the state space form \n\n\n\nFor this system, the drag and mass can be estimated as the1 following lumped parameters covered in lecture\n$$ d = \\frac{u_{ss}}{\\dot{x}_{ss}} $$\n$$\nm = \\frac{-d \\cdot t_{0.9}}{\\ln(1 - 0.9)}\n$$\nI drove the car at the wall with a PWM value of 120 (in the range of values used for Lab 5) to collect data needed to estimate the above variables. Below are the graphs showing the ToF data and corresponding velocity for the drive at the wall. The velocity was calculated by taking the difference in ToF values over the difference in time for each new ToF data. Data was piped into a CSV for later use via a notification handler with the same structure as used in Lab 5.\n\nDrive at Wall\n\nToF and Velocity Data\nFrom the steady-state velocity (2.459 m/s), 90% rise time (1.21 s) and speed at 90% rise time (2.213 m/s) printed in the upper right of the graph, as well as setting U to 1 N (unit step) we can now calculate m and d:\n$$\nd = \\frac{1\\ \\mathrm{N}}{2.459\\ \\mathrm{m/s}} \\approx 0.407\\ \\mathrm{kg/s}\n$$\n$$\nm = \\frac{0.407\\ \\mathrm{kg/s} \\cdot 2.213\\ \\mathrm{m/s}}{\\ln(1 - 0.9)} \\approx .391\\ \\mathrm{kg}\n$$\nFinally, we can define our state space matrices in terms of known quantities:\n\n\n\nSince we are only directly measuring ToF data X, the state space which will give us that output are the following C and D matrices:\n\n\n\nKalman Python Simulation\nInitialize Python KF\nFor the initial python simulation, the sampling time used for the Kalman filter was 95 ms, the same as my ToF rate. When I confirmed that the simulation was working, I then sped it up to the rate that my PID code loop runs on my arduino (20 ms). U_ss was calculated via u/step_size, where u = 120 and step size = 255. I estimated my ToF variance (dx = 30mm) by taking the average variance in data when statically measuring distance from the wall.\nThe below code was used to discretize my A and B matrices and define my C and state vector\n\nNext, I specified my initial process noise and sensor noise covariance matrices via the following equations from lecture.\n\n\n\n\n\nThe following code from lecture was used for my Kalman filter\n\nTesting KF Simulation (ToF Speed)\nI started with testing the simulation using the variables calculated in the initialization KF section. You can see that the Kalman fit is pretty good– it tracks the ToF well but isn’t so close that it completely disregards the position and velocity from the kalman state dynamics when a new ToF comes in.\n\ndt = 0.095 | dx = 0.47 | $\\sigma_1$ &amp; $\\sigma_2$ = 32.4 | $\\sigma_3$ = 57.5\nJust for a test, I tried to have my Kalman filter follow my ToF more closely. I achieved this by increasing the $\\sigma_1$ and $\\sigma_2$ terms which effectively put more trust in the ToF data values. Here is the result of doubling $\\sigma_1$ and $\\sigma_2$ terms. You can see how closely the Kalman filter tracks the ToF data.\n\ndt = 0.095 | dx = 0.47 | $\\sigma_1$ &amp; $\\sigma_2$ = 65 | $\\sigma_3$ = 57.5\nFor a final simulation test I wanted to check the other extreme: what happens if I effectively only trust the model? I did this by increasing $\\sigma_3$ by an order of 1,000,000 times larger than $\\sigma_1$ and $\\sigma_2$. You can see in the below graph that the Kalman filter is effectively only using the state space dynamics to predict the next distance value rather than ever meshing with the ToF data.\n\ndt = 0.095 | dx = 0.47 | $\\sigma_1$ &amp; $\\sigma_2$ = 32.4 | $\\sigma_3$ = 1,000,000\nTesting KF Simulation (PID Speed)\nI sped up my dt term to the PID loop speed of 20 ms to simulate how it will run at the faster PID loop speed when integrated onto the robot.\n\ndt = 0.02 | $\\sigma_1$ &amp; $\\sigma_2$ = 32.4 | $\\sigma_3$ = 57.5\nAgain, I felt as though my my Kalman values were tracking too close to my ToF, thus I increased $\\sigma_3$ to 170 (3x the original value) and left $\\sigma_1$ and $\\sigma_2$ constant\n\n$\\sigma_1$ &amp; $\\sigma_2$ = 32.4 | $\\sigma_3$ = 170\nOnboard Robot Kalman Integration\nInitialize Arduino KF\nAfter confirming that the simulation worked as expected, I integrated the code onto my car. The general workflow is as follows:\nThe below code runs in the main loop without any delays. The pid_start flag is sent over a bluetooth command along with the PID gains. runPIDLin() is responsible for running the Kalman filter and passing the outputs into the PID logic function. After the data arrays are filled they are sent to the computer over artemis by the sendPIDData() function.\n\nBelow is the runPIDLin() function. We can break down each function called\n\ncollectTOF() collects the next ToF value and is responsible for setting the update variable to true dependings on if the ToF value is new or not. The ToF value (new or old) is added to the global TOF1 array.\nkalman() is responsible for running the Kalman filter. Note that the runPIDLin() functions runs as fast as possible thus the kalman filter is especially useful in predicting a distance measurment when new ToF values are not ready. I found that I had to scale my input speed value by 1000 for a better kalman response with from the state space dynamics (this is discussed again at the end).\npid_speed_ToF() feeds the distance value from the kalman filter into the PID loop which ultimately sends a speed to the motors. Note that the pid_speed_ToF function is effectively the same as from Lab 5.\n\n\nHere is the kalman() function. Note that the inverse and transpose functions had to be swapped out for Arduino alternatives\n\nTest Arduino\nThere was extensive debugging required to implement the Kalman filter onto the robot. I will be showing three test cases in this section to summarize all of the robot integration work and results.\n\nI started by testing the Kalman filter state dynamics similar to how the kalman dynamics model was tested in the python simulation. I did this by effectively putting zero trust in my ToF data relative to my dynamics model by making $\\sigma_3$  an order of 1,000,000 times larger than $\\sigma_1$ and $\\sigma_2$. This yielded the following graph which proves that the Kalman filter is standalone and independent– it properly follows the system dynamics derived at the beginning of the lab when not fusing the Kalman predicted values with ToF.\n\n\nKalman Filter Dynamics Test\n\nI implemented proportional control and ran the robot at a wall with the target of stopping 300 mm (~1ft) away. With only proportional control, I was unable to avoid hitting the wall unless the robot went extremely slow. Here is a trial where the robot does hit the wall but is able to bounce off and still meet the 1 ft target. Note that the speed is constant (horizontal) during some of the run due to the speed floor that is implemented. You can also see the speed ceiling in the PD control at the beginning.\n\n\nKalman Filter Proportional Control Kp = .1\n\nKalman Filter Poportional Control\n\nThe PD Control worked really well. Relative to the proportional control above, you can see that the rise time does slightly increase as the derivative term is helping to slow the car down earlier, but it allows for effectively zero overshoot. If I continued to increase the proportional and derivative gains, I might have been able to achieve a similarly quick rise time with the derivative term still reducing overshoot. The robot stopped right about 1 ft away from the wall with little steady state error; as in previous labs, an integral term did not seem to be needed. You can see the implementation of a low pass filter to reduce derivative kick and overall noise spikes. From the graph you can see that the Kalman filter follows the ToF data fairly well and, as proved above, is able to make its own predicitions using the state dynamcis which is especially useful when new ToF data isn’t ready.\n\n\nKalman Filter PD Kp = .12 | Kd = 60\n\nKalman Filter PD Control\nVariable Discussion\nQuick recap of variables used to tune and their impacts:\n\nm and d: Although these parameters were derived from experimentally determined variables at the start, they can still be fine-tuned. A higher value of m corresponds to a car with greater inertia; it accelerates less in response to a control input. The d term mainly influences the max speed of the car (calculated by the Kalman filter) and how rapidly the speed decreases once the control input is removed.\nu: The control input, unlike the m and d terms, come directly from the PID controller and in theory probably should not be changed in order to tune the kalman filter. However, I found that scaling/ampliyfing it (as mentioned earlier in the lab) was a quick and effective workaround to better match the filter’s expected behavior.\n$\\boldsymbol{\\sigma}$: As previously mentioned in the lab, $\\sigma_1$ and $\\sigma_2$ represent the “trust” in the ToF data realitve to the model. For example, large $\\sigma_1$ and $\\sigma_2$ correspond to low confidence in the model’s predictions and make the filter rely more heavily on sensor measurments. $\\sigma_3$ is effectively the same but for the model. Large $\\sigma_3$ values represent more trust in the model than in the ToF measurments.\n\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Stephan Wagner’s site with help in implementing the python kalman simulation! ChatGPT was used to help plot graphs.\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-6/","title":"Lab 6: Orientation Control","description":null,"body":"Bluetooth Communication and PID/DMP Code\nPID code is handeled and sent over bluetooth in a very similar fasion to lab 5!\nMain Function\nHere is the turning PID part of the main function. The PID turning code waits until the start_time_pid_turn flag is set to 1 via the PID_TURN_CONTROL command that is responsible for sending the Kp, Ki, and Kd gains as well as sending the starting flag: ble.send_command(CMD.PID_TURN_CONTROL, \"1.5|0|40|90\") # P|I|D. The getDMP and runPIDROT() functions are covered in detail in the next sections. After the turning PID arrays are filled, the robot is then instructed to stop and the sendPIDTURNData() function is used to loop through all arrays and send them over to be piped into a CVS via my notification hander.\nMain Loop\n\nNotification Handler\n\ngetDMP() Function\nThe getDMP function is responsible for updating the global yaw_gy varaible whenever there is a new value, and if there is not (pretty rare) the previous value is used to avoid storing zeros in the yaw array. Also, it is worth noting that if we were deriving the yaw angle by taking the integral of the gyroscope’s angular velocity over time it would not make sense to then take the derivative. However, since the DMP is providing discrete angle readings, we do need to take these derivatives still.\n\nrunPIDRot() Function\nThe runPIDRot() function is responsible for calling the PID turning function (pid_turn_Gyro()) and ensuring that it has the current distance fed in as a parameter. The function also populates the PID arrays\n\npid_turn_Gyro() Function\nThere are three key aspects of the PID turning control loop:\n\nWhen I first was testing with proportional and PD control, I noticed that what was really happening was that the speed was just jumping between the floor value on the negative and positve side as seen in the below image. To account for this I decided that I needed to map the calculated speeds (in the range of 0-255) into the range scaled to my robot’s floor and ceiling. This was done using the Arduino map command speedTurn_set_mapped = map(speedTurn_set, 0, 255, minSpeedTurn, maxSpeedTurn). The result is that my robot is now using real PID control (which will be shown later) rather than just going between the PWM floor.\n\n\nNo Mapping Control\n\n\nA low pass filter was used on the derivative term to reduce noise and the effect of derivative kick. The alpha value was calculated through a slight trial and error method where I found a balance between reducing noise (from the filtered_d_term) but also reducing speed/amplitude as fast as possible when needing to slow down (from the current d_term). The alpha that optimized this trade off was 0.1.\n\n\nWhile testing for hours I noticed that regardless of my gains (I tried Kd terms on the order of 1000), my robot would not be able to stop in time and over shot its target. I realized that it was not a coding issue but rather the cars inability to change directions fast enough. I also noticed that the overshoot only happened on the first approach– if I picked the car up and replaced it at the beginning location after it had been running for a while the car was able to stop perfectly. To account for this, I have the car delay for 1 second at a low PWM before starting. This solved the issue completely!\n\n\n\nPID Control and Gains Discussion\nPID Gains\nAfter much testing, I decided that the best final gains were Kp=1.65 and Kd=130. The Kp term is high enough to adjust and continue moving even when at small angles from the target. At the same time, it is not so big that it overshoots a large angle from the target. The Kd term is responsible for slowing down the car as it approaches the target angle. It is large enough to help slow the car down and reduce overshoot. With hours of tuning, I realized that if I continued to increase the Kd term, there would be more instability as I osccilate quickly about the target distance. The progression of choosing and testing gains is shown later. I found that my robot was able to arrive within a degree or two of the target distance and thus without the presence of considerable external noise, I did not see the need to implement integral control as well.\nTesting\nDisturbance Correction (PD)\nHere are my two final disturbance tests. The first is with Kp=1.8 and Kd=50. You can see that the car slightly overshoots but is able to come within a few degrees of the 90 degree target each time it restabalizes.\n\nDisturbance Correction Kp=1.8 | Kd=50\nHere is the other final disturbance test with Kp=1.65 and Kd=130. You can see that for these gains, the robot overshoots less but is just a little worst at re-aligning exactly at 90 degrees. Thus while it overshoots less, it is slower when moving to a set angle (with the increaed Kd gain that helps it slow down earlier).\n\nDisturbance Correction Kp=1.65 | Kd=130\nHere is the plotted data after being sent over bluetooth:\n\nDisturbance Correction Kp=1.65 | Kd=130\nYou can certainly see some derivative kick with the increased Kd term, however, the LPF does take care of it for the most part.\nTurning Way Points\nTo start thinking about future applications of the PID controller I added waypoints that the robot would turn to. During navigation this can be implemented along side of the straightline PID controller; the robot doesn’t need to turn in an arc while it drives, instead it can drive straight, pivot, then drive straight again. In this example, the robot turns from 0 degrees to 90 degrees, then back to 0 degrees, then ends at 120 degrees:\n\nWaypoints\nHere is the graph for my waypoint setting:\n\nWaypoint Data\nYou can certianly see some more derivative kick, but again, it is filtered out well by the LPF.\nSampling Time Discussion\nThe IMU polling rate is set to 1.1 kHz in the line: success &amp;= (myICM.enableDMPSensor(INV_ICM20948_SENSOR_GAME_ROTATION_VECTOR) == ICM_20948_Stat_Ok);. The sampling time for our system is the DMP output rate ODR which is set in my setup function: success &amp;= (myICM.setDMPODRrate(DMP_ODR_Reg_Quat6, 2) == ICM_20948_Stat_Ok);. The 2 sets the ODR to an overall 549 Hz, plenty fast for the PID turning loop.\n$$ ODR = \\frac{\\text{DMP running rate}}{\\text{ODR setting}} - 1 $$\nPolling rate is 1.1 kHz (1100 Hz)\n$$ ODR = \\frac{1100}{2} - 1 = 550 - 1 = 549 \\text{ Hz} $$\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Stephan Wagner’s site for much of the lab but most specifically for implementing the DMP! ChatGPT was used to help plot graphs.\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-5/","title":"Lab 5: Linear PID control and Linear interpolation","description":null,"body":"Bluetooth Communication and PID Code\nData communication to and from the computer and Artemis were handeled similar to previous labs. The PID.CONTROL command is used to send the start flag and the Kp, Ki, Kd, and target distance: ble.send_command(CMD.PID_CONTROL, \".05|0|6|300\") # P|I|D. The Arduino recieves the gains:\n\nThe main loop is responsible for running the runPID() function which collects the ToF data and internally runs the pid_speed_ToF() responsible for calculating the speed based on PID control feedback. The calculated speed is then passed into the forward() and reverse() functions from Lab 4. The function is run until the PID data array is filled (500 in this case).\n\nBelow is the int pid_speed_ToF() function. Note that after calculating the PID speed is calculated, there are various IF statments to account for the motor deadband, direction, stopping tolerance, and max speed. Effectively, the function logic flows as follows:\n\nCalculate PID Speed from gains and error\nIf the speed is &lt;1 it means we are effectively at our target and can stop\nIf we are not yet close enough to the target we check to ensure our set speed is lower than the max speed (in either direction). If it isn’t we bring the speed down to maxSpeed\nIf the speed falls within our deadband range from Lab 4 (PWM of 35), the PWM signal is brought up to 35\nThe set speed is passed into the reverse() or forward() function based on its sign\n\n\nAfter the data is collected, it is sent back to the computer over Bluetooth via the sendPIDData() function. On my computer the data is piped into a CSV file via my notification handler. From there, the data is plotted for visualization.\nPID Control and Tuning\nRange/Sampling Time Discussion\nThe following code was implemented to ensure that new ToF values were returned at least every 35ms. This is vital in PID control as we want to make sure we are re-calculating our speed frequently as possible even if it means trading off some accuracy. If new values are not recieved fast enough, the robot risks running into the wall or not being able to react fast enough to sudden changes in surroundings.\n\nProportional Control\nFor this lab the car starts roughly 2m-4m from the wall and is intended to stop 300mm from the wall. As a result, ToF readings (in mm) start at 2000-4000. For this lab, the intention is to keep the car speed to no more than ~150. If we focus on the very start of running the car, the error is roughly 3000-300 = 2700. Thus, my propotional gain values (which get multiplied by the 2700mm error) were in the range of .05 - .08 throughout tuning to keep us in the 100-150 PWM when at these large distances from the wall at the start. When the error gets very small, the Kp term is not large enough to provide the minimum PWM to move the car. As a result, the deadband minimum speed was implemented.\nBelow are two videos of only proportional control implementation with the car starting at ~2500mm from the wall. The first is with Kp = 0.5 and the second with Kp = 0.8. You can see that with the increased proportional gain, the car was unable to stop which is why a Kd term is added in the next section:\n\nProportional Control #1\n\nProportional Control #1\nPD Control\nWhile soley propotional control proved to be fairly accurate (effectively stopping &lt;4mm from the target), overshoot and ramming into the walls was still an issue at higher speeds. Thus, since I wanted to try increasing my speed I have to implement a derivative term. The derivative term helps to slow the car down proportional to the slope of the error. As the car approaches the wall the error is decreasing resulting in a negative derivative term that helps reduce the overall speed. You can see that with the same Kp = .08 value that previously crashed the car we are now able to stop early enough to avoid crashing with the addition of a derivative gain.\nI ran the robot with the following gains Kp = .08 &amp; Kd = 6\n\nPD Control\n\nPD Control\nDiscrete Kd values can be seen as the ToF values are unfotunely slow. When there is not a new ToF reading, the derivative term is zero as the current and previous error terms are the same until a new ToF reading comes in. To address this issue we extrapolate. Effectively, the derivative term is only slowing the car down at discrete intervals which is not enough to slow the car down in time at much higher speeds.\nExtrapolation\nLoop Speed Discussion (no Extrapolation)\nMy ToF returns new data every 108.21 ms on average which corresponds to a rate of 9.24 Hz. This large delay leads to the derivative issue mentioned above. When the code is sped up to eleminate waiting for a new ToF reading, the speed of the loop is now 172.27 Hz.\nExtrapolation Implementation\nThe following extrapolation code was added to the runPID() function. Essentially, two distance arrays are used: tof_time[i] for ToF readings as they are ready and interpolated[counter] which stores interpolated data. Two time arrays are also implemented: tof_time[i] to store time intervals that the sensors collect data at (important for calculating slope) and times[counter] for constant running time (also used by the interpolator).\n\nProportional Control with Extrapolation\nI started with testing extrapolation with proportional control. After many many hours of debugging it finally worked (yielding the above extrapolation code)!\nHere is a run with Kp set to 0.1\n\nProportional Control - Extrapolation\n\nProportional Control - Extrapolation\nWhile the robot does eventually finish at the 1 ft target, it initially overshoots and has to backtrack. This is solved via implementing derivative control to help slow the robot down as the error decreases. When graphing the extrapolated data it follows the expected curve however would benefit from some low pass filtering in the future.\nPD Control with Extrapolation\nHere is the first test after addings the derivative term with extrapolation (PD control). Kp set to 0.1 and Kd set to 3\n\nPD Control #1 - Extrapolation\n\nPD Control #1 - Extrapolation\nWhile the robot does reach the final 1ft target, it slows down a little earlier than it should. To account for this, the Kp term was increased to 0.2. For this final test I also tested to see how far I could back up the car and still have it reach the target distance. Here is the final video with Kp = 0.2 and the car started roughly 2.7m from the wall.\n\nPD Control #2 - Extrapolation\n\nPD Control #2 - Extrapolation\nIn conclusion, when comparing the extrapolated and non-extrapolated results, we can see the car far more able to slow down accurately. This allows for a overall faster speed without overshooting the target and crashing. With near zero steady state error, I did not find it necessary to implement integral control at the moment. However, the infastructure is in the code; if I wanted to use it I would just have to pass through an integral gain and tune!\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Wenyi’s site for PID implementation code and Daria’s site for help with extrapolation. ChatGPT was used to help plot graphs.\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-4/","title":"Lab 4: Motor Drivers and Open Loop Control","description":null,"body":"Prelab\nSystem Wiring\nI decided to use pins 13, A14, A15, A16 for control on the Artemis. This pin proximity does increase risk of shorting connections, however it allows for a more compact design and greater area of the board to be used for mounting to the car rather than having to avoid largely seperated pins. Furthermore, according to the data sheet pins marked with a (~) indicate PWM capability which is required to send signals to the motor drivers.\n\nArtemis Schematic\nThe motor driver electrical schematic used on my car is shown below:\n\nDrivetrain System Wiring Schematic\nBattery Discussion\nThe Artemis and the motor drivers/motors are powered by separate batteries to help ensure operational stability, protect components, reduce noise, and increase battery lifetime. The two car motors can act as a disruptive inductive load, potentially creating large amounts of noise and posing a damage risk to sensitive parts. Thus powering the Artemis by a second battery allows the motors to run for longer and protect the Artemis circuit (all connected by signal wires) from the motor interferance and inductive load.\nLab Tasks\nPower Supply and Oscilloscope Hookup\nOne motor driver was tested at a time by connecting the inner two OUT pins to the positive scope probe and the outer two OUT pins to the ground scope probe. I also connected VIN and GND to the power supply to power the driver. The power supply is set to 3.7V to simulate the 3.7V that would be supplied by the 850mAh motor battery. Below is a picture of the setup (the power supply and oscilloscope probing wires are drawn in to show the setup used to obtain the PWM signal before I soldered the parts to the car):\n\nScope and Power Supply Connection to Motor Driver\nThe following code was used to visualize the motor driver output:\n\nThe analogWrite(AB1IN_LEFT,100) line indicated a 40% (100/255) duty cycle to pin 16. This was captured on the oscilloscope:\n\nOscilloscope PWM Output (40% Duty)\nMotor Testing\nThe above code used to see the PWM signals on the scope were also used to run one side of wheels:\n\nOne Side Test\nAfter confirming that both motor drivers successfully powered the motors, I tried running the car all together using the 850 mAh battery using the following code:\n\n\nBoth Wheels Spinning (with battery)\nComplete Hardware Integration on Car\nBelow are images of the car after mounting all components. Holes were drilled and zip ties were used to strap down the IMU and both motor drivers at the front. Zip ties were also used to bundle the Artemis and 750mAh battery as well as for wire managment. Double sided tape was used to mount the two ToF sensors (one on the side and one at the front) and the Artemis/battery module at the rear.\n\nTop of Car\n\n    \n        \n        Bottom of Car\n    \n    \n        \n        Battery Connection on Bottom\n    \n\n\nFront of Car\nLower PWM Limit\nI found that the minimum PWM value for which the robot needs to move forward, backward, and on axis by starting with a arbitrary small value and increasing it by 5 until the car no longer stalled. I found that on a fully charged battery the forward and backward lower limit PWM value is 35 and 110 for spinning on axis.\nHere is a video of testing using those PWM values to go forward, in reverse, then spin on axis in both directions:\n\nLower PWM Limit\nOpen Loop Testing and Calibration\nWhen first testing the car’s straightline preformance, it would instantly begin to veer to the right. I also noticed that when traveling in reverse the car had the same issue where the right side lacked power. To account for this I added a calibration factor to increase the PWM signal for the right set of wheels. Initially I went about this by simply adding a calibration factor to the PWM rather than scaling it via a multiplicative calibration factor. While I was able to get the car fairly straight doing this, it only really worked for a set speed. Given this, I decided to switch to a scaling calibration factor which you can see implemented in the code below. I started both scaling factors at 1 and increased them by .05 until I recieved steady straightline results (visible in the Open Loop Test video).\n\n\nspeedLine is the stright line speed for forward and reverse\nspeedTurn is the turning speed\ncorrection_f is the calibration factor for forward wheel rotation (currently 1.05)\ncorrection_b is the calibration factor for reverse wheel rotation (currently 1.3)\n\nTo test a range of car capabilities, I had the car move straight, then in reverse, then rotate on axis in both directions before moving straight left at the end (note each tile is 13“x13“). The sequence of actions is set in the main loop() which gets called when the START_DATA_COLLECTION command flag is run over bluetooth.\n\nOpen Loop Test\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Wenyi’s site for my wiring setup, initial motor testing code, and general outline for creating funtions to drive forward, spin right, etc. Special thanks to all TA’s that helped debug my electronics and car for hours before we realized I probably needed a new one!\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-3/","title":"Lab 3: Time of Flight Sensors","description":null,"body":"I2C Address and Time-of-Flight Sensor Discussion\nTwo time of flight sensors will used and ultimately mounted on the car to provide different points of view to help the robot naviate; one of my ToF sensors will be mounted on the front center of the car and the other between the two wheels on one side. This will allow me to keep a set distance from walls to the side as well as avoid obstacles and navigate with vision at the front.\nSince we want to use two ToF flight sensors which have the same I2C address, we use the XSHUT pin on one of the sensors to shut off one ToF which modifying the I2C address of the other. It can then be restarted again to function simultaniously with the other. Below is the code to execute this initialization:\n\nPer the data ToF data sheet, the default I2C address is 0x52 (0b 0101 0010).\nUsing the Example05_Wire_I2C.ino example sketch, I was able to scan for connected I2C devices:\n\nI2C Device Scanning\nFrom the scan we can see the Tof device address as 0x29 (0b 0010 1001). Since the least significant bit is used to indicate read/write, it is soley a matter of shifting the 7-bit 0x29 address left by one bit to make space for the read/write bit that appears in the data sheet. Thus, the scanned address matches the data sheet as it is just a shift left away from matching the 0x52 8-bit address.\nPhysical Connection\nIn the below images you can see the battery leads soldered to the QWICC connect cables and the ToF sensors wired as outlined in the schematic:\n\nWiring Schematic\n\nToF sensor connected to QWIIC breakout board\n\nSoldered Battery Pack\nTwo ToF Sensors In Parallel Test\nFrom the following video we can see the two ToF sensors working in parallel. I noticed that when the clearance for my ToF sensor drops below 20 mm, they tend to output 0 mm. However, this is to be expected since according to section 3.3 of the sensor data sheet, the minimum ranging distance is 4 cm. Overall, the sensors are accurate outside of this range.\nI decided to use the long ToF mode distanceSensor1.setDistanceModeLong(). According to the data sheet: “long distance mode allows the longest possible ranging distance of 4 m to be reached.” In a classroom environment I believe that this longer distance will prove more useful for mapping even though it is at the cost of higher resolution at shorter distances.\n\nTwo ToF Sensor Testing\nToF Sensor Speed\nI tested the speed of my ToF sensors in two ways. The first was by printing the Artemis clock to the Serial as fast as possible and printing new ToF sensor data from both sensors only when available. The second was by testing the speed when called over bluetooth and compare it to the IMU.\n\nI used the following function to visualize and quantify the gap between each ToF data collection:\n\n\n\n    \n        \n        Speed Test Frame 1\n    \n    \n        \n        Speed Test Frame 2\n    \n    \n        \n        Speed Test Frame 3\n    \n\nFrom the above three images you can see that the average gap between ToF sensor collection is 90 ms, corresponding to a rate of 11 Hz. Both sensor 1 and sensor two print at roughly the same rate.\n\nI created a function collectTOF() to collect my ToF data in order to ensure the code doesn’t hang while it waits for the sensor to finish a measurement. It is called from the main loop when one of the two ToF sensors are ready AND my start flag is true. The function populates a time and two ToF arrays with data. The data is parsed through via case GET_TOF_READINGS to be sent over bluetooth.\n\n\nAfter collecting data for 5 seconds (using my START_DATA_COLLECTION and STOP_DATA_COLLECTION command flags) the following number data points were collected from the IMU (function shown in Lab 2) and ToF sensors relative to the number of cycles through my main loop. This method helps eliminate the delay from print statments in the first speed test:\n\nIMU and ToF Counters\nFrom the counters we can see that the ToF sensors were considerably slower than the IMU at recieving data and thus would be the limiting factor. After 5 seconds of data collection this corresponds 10 Hz for the ToF and 98 Hz for the IMU.\nToF Sensor Data (Over Bluetooth)\nHere I created a Time vs. Distance graph of ToF data collected on the Artemis then sent over bluetooth:\n\nDistance Testing via Bluetooth\nHere is another graph where I simultaniously collected ToF and IMU data for 5 seconds over bluetooth and graphed them on the same time axis. The complementary filter from Lab 2 was used for the IMU data:\n\nAngle and Distance Collection\nToF Accuracy\nTo quantify the accuracy of the ToF sensors I collected 10 seconds of data at three distances and graphed the data vs. time as well as the set target distance:\n\n100 mm Test\n\n150 mm Test\n\n200 mm Test\nAll around from the graphs you can see that the time of flight sensors are fairly accurate at a range of distances. While the testing setup was fairly precise, a few milimeters of variance is likely due to the human error in trying to perfectly align the placement of the sensors along my ruler. Nonetheless there is certainly some higher frequency noise in the ToF sensors which could likely be reduced by a LPF.\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Wenyi’s site for my wiring setup, ToF sensor initiation, and sketch used to  print out distance sensors in my serial monitor to test speed. ChatGPT was used to help plot CSV data and format graphs.\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-2/","title":"Lab 2: IMU","description":null,"body":"IMU Setup\nAD0_VAL &amp; Initial Data Observations\nThe AD0_VAL represents the last bit of the I2C address. In our case, 1 is set as the default and that shouldn’t be changed unless the ADR on the board is closed via solder and then should be set to 0.\nAfter testing with the example code as well as the lecture 4 code, it appears that the accelerometer and gyroscope data print as expected. Three axis are printed for both sensor as well as the corresponding unit (mg for acceleration and DPF for the gyroscope). As discussed in lecture, in the data you can see accelerations and rotations being tracked but not absolute position; changes in the printed values only occur with movement. Additionally, you can see that the changing values are dependent on the axis being rotated about and the sensor being observed. When rotating around the z-axis you can see that the accelerometer data does not change, however the gyroscope does. When accelerating the board along the x-axis you can see a change in value for the accelerometer x-axis but not the gyroscope.\n\nArtemis and IMU Connection with BLUE LED Indicator\nAccelerometer\nAccelerometer Data to Pitch and Roll Conversion\n\n\nVideo of IMU Testing - full screen to reduce blur\n\n    \n        \n        0°\n    \n    \n        \n        Pitch @ -90°\n    \n    \n        \n        Pitch @ 90°\n    \n    \n        \n        Roll @ -90°\n    \n    \n        \n        Roll @ 90°\n    \n\nAs you can see from the frozen frames, the accelerometer is very accurate with vary little variation in angle from the expected value. As a result I do not think it is nessesary to do a two-point calibration.\nData Collection and Plotting Code\nThe following code was used to collect the data in arrays and then use Juypter to pipe the data from the Artemis into a CSV file and graph. Note that as I added more arrays to store more data (LPF, Gyro, Complementary Filter) I simply added more columns to the csv via the notification handler. The graphs will be shown later in the lab for analysis.\nArtemis Aruino Code:\n\nJupyter Code:\n\nFourier Transform and Low Pass Filter Plotting\nThe raw data shows some noise in the higher frequencies however it is fairly negligable. This is due to the fact that the IMU has a low pass filter implemented already. Regardless, I will add a low pass filter\nWhen collecting dat in the proximity of the running car, the most noise appeared to be in the range of 0 Hz and 5 Hz; I will make the cutoff at 5 Hz. The lowpass filter effects the output by limiting faster frequencies (which we are defining as noise) from being shown in the data. If the frequency chosen is too small, you will still have unwanted noise in the smaller frequency range. However, if you pick too high of a cutoff frequency you run the risk of ignoring data points that may actually be important and a correct reflection of the robot’s movement (maybe a sharp turn on a flip).\nIn order to apply a low pass filter I had to calculate my alpha value as 0.0876 using following equations:\n$$\\alpha = \\frac{T}{T + RC}$$\n$$ f_c = \\frac{1}{2\\pi RC} $$\n\nT = sampling rate\n$f_c$ = cutoff frequency\n\n\nRaw and Fourier Transform Data with Low Pass Filter - Car in Proximity\n \n\nRaw and Fourier Transform Data with Low Pass Filter - Hand Osscilations\n \n\nRaw and Fourier Transform Data with Low Pass Filter - Hitting Table\nYou can see that the low pass filter is successful in reducing unwanted noise in the accelerometer data. This is especially clear in the final graphic (Raw and Fourier Transform Data with Low Pass Filter - Hand Osscilations) where the LPF works to ignore the spikes in magnitude that comes from hitting the table.\nGyroscope\nEquations to compute pitch, roll, and yaw angles from the gyroscope:\n\nGyroscope vs. Accelerometer Data\nWhen first collecting the gyroscope readings I noticed that the data did not match the accelerometer data. I realized that due to the default axis of the gyroscope, the pitch and roll for the gyroscope really corresponded to the roll and pitch of the accelerometer respectively (and make the pitch negative).\n\nInitial Gyro vs. Accelerometer Readings (Flipping Needed) \nAfter making those changes, I noticed that there was still drift from the gyroscope over time, likely due from integrating the error in each step. However, I did find it interesting that the gyroscop provided cleaner and smoother data during quick direction changed (going from -90 to 90 degrees and back). Thus while the gyroscope alone may not be highly accurate, it is still stable.\n\nRaw Gyro Data vs. Accelerometer Readings \nTo observe the effects of changing the sampling rate, I added delays in my case GET_ACC_READINGS command code FOR loop to slow down the data collection. I noticed that a delay of 10 ms added some choppiness to the plotting without a significant increase it collection time. However, adding a 100 ms delay significantly increased the data collection time as well as the choppiness in the plot. The gyroscope, which I found was especially good at tracking quick changes of direction smoothly is now not nearly as clear. Additionally, you can see the plot jumping around for smoother IMU movements as the gaps between time intervals is increased.\nComplementary Filter Implementation\nThe following code was used to imlpement my complementary filter:\n\n\nComplementary Filter Gyro vs. Low Pass Filter Accelerometer\nFrom the results you can that with an alpha value of 0.0876 the combined measurements from the accelerometer and gyroscope significantly increases stability (which comes from the gyroscope) and accuracy (from the low pass filter accelerometer).\nSampling Data\nSpeed Up\nI took a few measures to speed up the execution time for my main loop:\n\nRemoved the part in my code where I wait for IMU data to be ready (for example checking(myICM.dataReady()) to move through the command loop. Instead I check if data is ready in the main loop and if it is I call the function collectIMU() to compute the pitch, roll and yaw. After computing I add them to their respective arrays and iterate through those arrays with a different command (that does not affect the resolution as data is already collected).\nRemoved debugging print statments in my command to get IMU data\nI use flags to start/stop data recording\n\nWhile my IMU was able to sample new values farily quickly (~ 350 Hz) after cleaning up my code, the main loop runs significantly faster than my IMU produces new data. This is evident when comparing the IMU_Count variable (which only runs when data is collected) to the Total_Loops (which counts the number of times cycled through the main). The Total_Loops is larger on the magnitude of 10-100x which means that the IMU is the holdup.\nCode of main loop function:\n\ncollectIMU() function:\n\nJupyter code to start/stop data collection via setting a global start variable to 1 or 0 within the START_DATA_COLLECTION and START_DATA_COLLECTION commands:\n\nThe old case GET_ACC_READINGS command was called in Jupyter after stopping data collection to then re-popoulate the csv file with new values.\n\nCSV proving population of time-stamped IMU data in arrays\nData Storage\nI decided that it would be best to have seperate arrays for storing accelerometer and gyroscope data rather than one large one. This was partially because I decided that it would be easier to organize and parse through the data using different arrays to compartmentalize the data before sending them over bluetooth. I also found it easier to create a CSV from the seperate arrays in Jupyter.\nEach of these arrays contain floats as the gyroscope and acceleration naturally output decimal values. With a double data type being twice the size of a float (64 vs 32 bits), I decided that a float was the best data type for these sensor arrays.\nI have a total of 10 floats arrays for a total of 40 bytes at a time:\n\n1 for time\n2 for accelerometer roll and pitch\n2 for LPF roll and pitch\n3 for gyroscope roll, pitch, and yaw\n2 for complementary filter data\n\nIn lab 1b global variables use 30,648 bytes. This lab we added the above arrays to send IMU data. If the Artemis board has 384 kB of RAM, then 353,352 bytes of dynamic memor remain which allow us to store 353,352/40 = 8833 data points. With an average step time of 2.86 ms (shown below) we get a sample rate of 349.65 Hz. This corresponds to 25.26 seconds of IMU data collection.\n5 Seconds of IMU Data\n\nProving 5 Seconds of IMU Data\nI used one of my CSV files as an example of collecting at least 5 seconds of data and sending it over bluetooth. To do this I took the difference between the first time stamp and the last time stamp in my proximityFinal.csv file:\n\nRC Stunts\n\nStunt 1\n\nStunt 2\nThe car is quick at direction changing and accelerating. When spinning it is able to hold its position on the ground without drifting much. Note that the car’s speed can not be changed while moving, it can only stop and change directions.\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Daria’s site for code debugging in my complementary filter as well as visually understanding how to effectively display my plots. ChatGPT was heavily used to write plotting code for the Raw, FFT and LPF data. It also helped me write my FFT function as the provided link had some syntax error and missing pictures.\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-1/","title":"Lab 1: Artemis Setup and Communication","description":null,"body":"Lab 1a\nDuring section 1a of the lab I installed the Arduino IDE and established a wired connection to communicate with the Artemis Nano. To connect I had to select the correct board and port in the Arduino IDE. Then, to test the connection and explore the Arduino environment I completed the following assigned example sketches in the Arduino IDE:\n\nBasics_blink\nApollo3_serial\nApollo3_analogRead\nPDM_microphoneOutput\n\nBlink\nYou can see the Artemis board flash a bright blue led\n\nBlink test video\nSerial\nHere we can see the Artemis recieves the string and echos it back\n\nSerial output test\nanalogRead Temperature Sensor\n\nTemperature sensor test\nMicrophone Output\nFrom the video you can see the Artemis microphone successfully picking up the difference in sounds in the serial monitor\n\nMicrphone output test\nLab 1b\nCodebase and BLE\nBluetooth (specifically Bluetooth LE) at a high level is used to establish a connection between my computer and the Artemis:\n\n\nBluetooth LE radio acts like a community bulletin board where Computers (community members) can connect to read the board. If the radio is a bulletin board we call that a peripheral device (the Artemis in this case) and it is responsible for posting data. If the radio is a reader (central device) it reads from any of the bulletin boards. Essentially, central devices view the services, get the data, then move on, all within a few milliseconds allowing multiple central devices can get data from one peripheral.\n\n\nServices are identified by unique numbers known as UUIDs. The ability to define services and characteristics depends on the radio you’re using and its firmware. Bluetooth LE peripherals will provide services, which in turn provide characteristics.\n\n\nThere are four things that a central device can do with a characteristic: Read, Write, Indicate, and Notify\n\n\nThe codebase is collection of source code files that make up our system. Some important components:\n\n\nThe Artemis’ unique UUID and Mac address allow for undisrupted communication and transmission of BLExCharacteristics\n\n\nble_arduino.ino is the code running on the Artemis, edited in the Arduino IDE\n\n\nEString is used when transmitting strings from the Artemis to your computer\n\n\nRobotCommand.h is used when handling a robot command that the Artemis receives and is of the string format &lt;cmd_type&gt;:&lt;value1&gt; &lt;value2&gt;|&lt;value3&gt;|…\n\n\nDemo.ipynb is where you find the python code sending commands to the Artemis\n\n\nSome relevant functions used to communicate between the computer and Artemis:\n\nsend_command(cmd_type, data) to send a command\nble.connect() and ble.disconnect to connect with the Artemis\nreceive_string(uuid) to recieve a string from our board\nstart_notify(uuid, notification_handler) to activate the notification handler\nble.bytearray_to_string(byteArray) to convert recieved data into string\n\n\n\nConfigurations and Setup\n\n\nI started with installing venv: python3 -m pip install --user virtualenv\n\n\nI created the “FastRobots_ble” virtual environment inside my project directory: python3 -m venv FastRobots_ble\n\n\nI activated the virtual environment: source FastRobots_ble/bin/activate\n\n\nI downloaded the provided ble_robot_1.2 codebase into my project directory\n\n\nIt is now time to start the Jupyter server: jupyter lab\n\n\nUpdated the Artemis MAC Address on the Computer. Run the ble_arduino.ino file in the Arduino IDE and check the serial monitor the MAC address:\n\n\n\nMAC Address\n\nGenerate new UUID: run from uuid import uuid4 and uuid4(). Input the generated UUID into the #define BLE_UUID_TEST_SERVICE line in ble_arduino.ino and into the ble_service: line in connections.yaml\n\n\nconnections.yaml\n\nble_arduino.ino\n\nConnect to the Artemis Nano via BLE\n\n\n\nSuccessful BLE Connection\nTask 1\nI sent a string value from my computer to the Artemis board using the  ECHO command and the computer recieved and printed the augmented string\nArduino Code:\n\nJupyter Lab Code:\n\n\n\nECHO Output\nTask 2\nI sent three floats to the Artemis board using the SEND_THREE_FLOATS command and extracted the three floats in the Arduino sketch\nArduino Code:\n\nJupyter Lab Code:\n\n\nSEND_THREE_FLOATS Output\nTask 3\nI added a GET_TIME_MILLIS which makes the robot reply write a string to the string characteristic. GET_TIME_MILLIS had to be added to the cmd_types.py file. GET_TIME_MILLIS had to be added to cmd_types.py to run. Note that the output looks the same as in task 4.\n\nTask 4\nI setup a notification_handler function to receive the string value from the Artemis board and, in the callback function, extract the time from the string.\n\n\n\n\nNotification Handler Output\nTask 5\nI made a twenty-five step loop that gets the current time in milliseconds using the GET_TIME_MILLIS function to then be processed by notification_handler(). From my output shown below you can see that there was an average 33.5 ms gap between the prints. This translates to 29.85 message transmissions per second. With each message being 9 bytes (1 char per each string sent), this results an effective data transfer rate of 269 bytes per second for this method.\n\n\nGET_TIME_MILLIS Loop Output\nTask 6\nI created a command SEND_TIME_DATA that loops though to add generated time steps via the millis() function and then stores them in an array. Then, in SEND_TIME_DATA I loop through the array and send each data point as a string to my laptop to be processed. SEND_TIME_DATA had to be added to the cmd_types.py file. Note that millisArray[i] is defined as a global array.\nArduino Code\n\nJupyter Code:\n\n\nSEND_TIME_DATA Output\nTask 7\nI created a second array to store fahrenheit temperature readings with the same length as the one used in task 6. Each index in both global arrays (millisArray[] and tempArray[]) correspond to each other. The command GET_TEMP_READINGS loops through both arrays concurrently and sends each temperature reading with a time stamp. The notification handler parses these strings and populates the data into two lists. Note that GET_TEMP_READINGS had to be added to the cmd_types.py file.\n\n\nTemp and Time Output\nTask 8\nRate wise, it is clear from the time steps in tasks 5 vs. 6 that method one is considerably slower at recording data than method two. This is because method one has to wait until the Artemis sends data to the computer after every round of collection before recording again. Instead, the second method can effectively record data as fast as its slowest sensor, thus producing data that may be more accurate but at the expense of a delayed reception on the client’s end. This could result in a slower response time from the robot and thus is less applicable if the robot needs to make time-sensitive decisions from sensor data. For an open-loop test where we do not care as much about real-time feedback, method two may be more useful as the faster data recording would provide higher resolution.\nIn order to determine how quickly the second method records data, I had to increase the number of loop iterations to 100 in order to see a difference in time steps. The first element is T: 104510ms and the 100th is T: 104512ms which translates to data being recorded every 0.02ms on average (considerably faster than the 33.5 ms gap in task 5).\nThe millis() int variable and getTempDegF() int variable are both stored as ints of 4 bytes each for a total of 8 bytes. As printed by the Arduino IDE output, global variables use 30648 bytes. If the Artemis board has 384 kB of RAM, then 353,352 bytes remain allowing us to store a total of 353,352 bytes/8 bytes = 44,169 data points without running out of memory.\nDiscussion and Conclusion (Lab 1A &amp; 1B)\n\nLearned about what functions are responsible for communication between my computer and Artemis and how the commands (ECHO, GET_TIME_MILLIS, etc.) are passed in via RobotCommand.h\nAt first I was confused about the relationship between different data types and their byte size. However, the later questions in the lab made it clear how ints vs. strings require different number of bytes as well as how Estring char are used to send those types to the computer\nThe largest problem I faced was understanding the parameters needed for the notification handler!\n\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Daria’s site for code debugging and specific help with SEND_TIME_DATA and GET_TEMP_READINGS. ChatGPT was used for Lab 1B code debugging and website formatting/development.\n","path":null}]