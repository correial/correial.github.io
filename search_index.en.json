[{"url":"https://correial.github.io/","title":"About Me","description":null,"body":"\n\n\n  Lucca Correia\n  \n    \n      \n    \n  \n  \n  \n    \n  \n\n\nSenior at Cornell University pursuing a B.S. in Mechanical Engineering with a focus in Robotics\n\n\n\n\n\n  On campus, I work in the \n  Helbling Lab \n  designing autonomous insect-scale robotic platforms as well as play for the Cornell United Soccer Club Team. \n  Last year I served as the Mechanical Subteam Lead for the Cornell Nexus Project Team. \n  Most recently, I interned as a mechanical engineer at Foundation, a Humanoid Robotics Company as well as completed Fast Robots, \n  an applied course in robotics and control systems.\n\n\n\n\n\n\n\n","path":null},{"url":"https://correial.github.io/resume/","title":"Resume","description":null,"body":"\n","path":null},{"url":"https://correial.github.io/Portfolio/","title":"My Projects & Experience","description":null,"body":"","path":null},{"url":"https://correial.github.io/Portfolio/foundation-robotics/","title":"Mechanical Engineering Intern @ Foundation","description":null,"body":"This past summer (2025) I had the incredible opportunity of interning at Foundation, a startup humanoid robotics company based out of San Fransisco, CA. During my time there I worked as an extremely hands on mechanical/robotics engineer where I designed manufacturing fixtures and was partially responsible for the assembly, workflow, debugging, and build instructions of entire Phantom 1 Humanoids. Below are a few internship highlights:\nHumanoid Assembly &amp; Debugging\n\nIndependently completed the assembly of entire Phantom MK1 Humanoids including structures, linkages, motor encoder soldering, power and signal harnesses fabrication, actuator calibration\nComplete initial robot bring-up via simulation that involved URDF visualization and actuator signals\nWorked on manufacturing floor to complete humanoid repairs and often independent debugging\n\n\n  \n    \n    Independent entire humanoid assembly\n  \n  \n    \n    Lower body actuator debugging\n  \n\nManufacturing Design Projects\n\nDesigned various manufacturing and work holding fixtures in OnShape for CNC milling. Examples include a jig to clamp down actuator encoder magnet rings to be milled down as well as an ankle zeroing fixture to establish neutral ankle position during bring-up\nUtilized CAM software to generate GCODE paths for the various work holding fixtures\nSet up and operated 3-axis CNC mill for fabrication of the jobs\n\n\n  \n    \n    Ankle Zeroing Fixture Model\n  \n  \n    \n    Ankle Zeroing Fixture GCODE\n  \n\nThe encoder magnet rings were one of my key design and machining projects. The team needed a repeatable process to remove a 3 mm bore and, if required, enlarge the ID to 11 mm. My contributions included:\n\nFixture Design: Created a CNC fixture in CAD to clamp the magnet ring without damaging the encoder magnet. Key features included a pedestal to protect the magnet, precise pocket depth for clamping, minimal offset between clamp surfaces to prevent deformation, and a transition-fit pocket for accurate alignment.\nCAM &amp; Machining of Fixture: Generated tool paths, researched feeds/speeds, selected appropriate bits, and programmed GCODE for the mill.\nRing Modification: Machined AISI 430 housings using a 4-flute ¬º‚Ä≥ TiAlN-coated carbide end mill with conservative depth-of-cut parameters. Programed a circular toolpath in CAM followed by a larger diameter bit for a 70 ¬µm finishing pass.\nDocumentation: Authored detailed work instructions for technicians to reliably repeat the modification process.\n\n\n  \n  \n    \n    Before and After Modification\n  \n  \n  \n    \n      \n      Final Finishing Pass\n    \n    \n      \n      Ring GCODE\n    \n  \n\n\n  \n  \n    Work Instructions and Workflow Process\n    \n      While completing humanoid assembly, I developed comprehensive CAD-based build \n      instructions and an assembly workflow for the entire lower body. I collaborated \n      with process engineers and technicians to gather feedback and refine both the \n      instructions and overall workflow for efficiency and clarity.\n    \n  \n  \n  \n    \n    Humanoid CAD used for comprehensive work instructions\n  \n\n","path":null},{"url":"https://correial.github.io/Portfolio/fast-robots/","title":"MAE 4190 Fast Robots","description":null,"body":"This page showcases my work in MAE 4190 Fast Robots, a course centered on the systems-level design and implementation of dynamic autonomous robots. Over the semester, I designed and fabricated a fast autonomous car with dynamic system modeling and reactive control via integrating gyroscope and time-of-flight sensor feedback on an embedded processor. The course also explored the advantages of partial off-board computation, low-latency software, and noise-tolerant implementation.\nHighlights from Each Lab\nBelow are highlights from each lab building up to the final lab where I achieved fully autonomous navigation and path planning via real time localization and linear/angular PID control. For detailed documentation of each lab with code reference my\nFast Robots site.\nLab 1: Artemis Setup and Communcation\nKey Takeaways:\n\nInstalled and configured the Artemis successfully\nSet up a reliable communication link between Artemis (peripheral) and computer (client)\nBuilt methods for both real-time and batch data collection to compare responsiveness and accuracy in sampling\nCustomized UUIDs to avoid device conflicts and wrote Python scripts for BLE command transmission and processing\n\nLab 2: IMU\nKey Takeaways:\n\nConfigured ICM-20948 IMU over I2C, verified accelerometer and gyroscope readings.\nConverted accelerometer outputs to pitch and roll; validated accuracy across ¬±90¬∞.\nImplemented FFT + low-pass filter (cutoff 5 Hz) to characterize and reduce noise while preserving motion signals.\nIntegrated gyro drift-prone data with accelerometer stability using a complementary filter (Œ± = 0.0876).\nAchieved ~350 Hz sample rate, 25 seconds of buffered IMU data, and confirmed smooth motion capture during stunts.\n\n\nRaw and Fourier Transform Data with Low Pass Filter - Hand Osscilations\n\nComplementary Filter Gyro vs. Low Pass Filter Accelerometer\nLab 3: Time of Flight Sensors\nKey Takeaways:\n\nUsed XSHUT pin to reassign I2C addresses, enabling two ToF sensors in parallel.\nWired sensors to Qwiic breakout with soldered battery leads, tested mounting layout.\nVerified accuracy across 100‚Äì200 mm; identified noise below 40 mm due to sensor limits.\nMeasured ~11 Hz sampling rate; confirmed ToF was the bottleneck compared to ~98 Hz IMU.\nCollected synchronized ToF + IMU data over BLE, validating angle/distance correlation.\nCharacterized ToF noise\n\n\n150 mm Test\nLab 4: Motor Drivers and Open Loop Control\nKey Takeaways:\n\nDesigned drivetrain wiring: Artemis pins (13, A14, A15, A16) to dual motor drivers with PWM control.\nUsed separate batteries for Artemis vs. motors to reduce noise and protect sensitive electronics.\nVerified PWM duty cycles on oscilloscope and tested forward/reverse/spin maneuvers.\nDetermined lower PWM thresholds (35 forward/reverse, 110 spin).\nCalibrated wheel imbalance with multiplicative correction factors (1.05, 1.3) to achieve straight-line motion.\nFully integrated IMU, ToF, motor drivers, and power onto the chassis for open-loop tests.\n\n\n\n  \n    \n    Front of Car\n  \n  \n    \n    Top of Car\n  \n\nLab 5: Linear PID Control and Linear Interpolation\nKey Takeaways:\n\nImplemented BLE command PID_CONTROL to send PID gains (Kp, Ki, Kd) and target ToF distance to the Artemis.\nDeveloped pid_speed_ToF() function with logic for tolerance, saturation, motor deadband, and direction switching.\nTuned Proportional control (Kp = 0.05‚Äì0.08) to keep PWM speeds reasonable at large errors; deadband added for small errors.\nAdded Derivative control (Kd ‚âà 6) to slow the robot proportionally to error slope, preventing overshoot into the wall.\nFound ToF sampling limited to ~9.24 Hz, causing discrete jumps in derivative term.\nImplemented extrapolation to achieve ~172 Hz loop speed, interpolating distances between ToF readings.\nVerified with PD + extrapolation (Kp = 0.2, Kd = 3): robot could start 2.7 m from wall and still stop at 1 ft target without overshoot.\nDemonstrated near-zero steady-state error at higher speeds, eliminating need for integral term.\n\n\nPD Control\n\nProportional Control #1\n\nPD Control #2 - Extrapolation\nLab 6: Orientation Control\nKey Takeaways:\n\nImplemented PID turning control loop using IMU DMP yaw data.\nMapped PWM outputs into robot‚Äôs floor/ceiling bounds to achieve smooth PID instead of binary switching.\nAdded low-pass filter (ùõº = 0.1) on derivative term to reduce noise and derivative kick.\nFixed overshoot by inserting 1-second low-PWM delay before rotation.\nTuned gains to Kp=1.65, Kd=130, achieving ¬±2¬∞ accuracy in disturbance tests and waypoint navigation.\nVerified IMU DMP sampling at ~549 Hz, sufficient for high-speed control loops.\n\n\nNo Mapping Control\n\nDisturbance Correction Kp=1.65 | Kd=130\n\nDisturbance Correction Kp=1.65 | Kd=130\nLab 7: Kalman Filter\nKey Takeaways:\n\nModeled car dynamics with drag and mass parameters estimated from ToF velocity profiles\n\nm ‚âà 0.39 kg, d ‚âà 0.41 kg/s\n\n\nBuilt Python Kalman simulation to fuse ToF data with state-space dynamics\n\nTested trust weighting by varying sigma1, sigma2, sigma3\n\n\nConfirmed filter could run at ToF sampling rate (95 ms) and faster PID loop rate (20 ms)\nIntegrated filter on-board: predicted state when ToF was unavailable, improving control continuity\nDemonstrated proportional control overshot wall stops, but PD + Kalman achieved smooth approach and near-zero overshoot at 300 mm target\nDiscussed parameter tuning:\n\nm, d set dynamics\nu scaling improved model fit\nsigma values balanced model vs. sensor trust\n\n\n\n\nToF and Velocity Data\n\n\n  \n    \n    dt = 0.095 | dx = 0.47 | $\\sigma_1$ &amp; $\\sigma_2$ = 65 | $\\sigma_3$ = 57.5\n  \n  \n    \n    dt = 0.02 | $\\sigma_1$ &amp; $\\sigma_2$ = 32.4 | $\\sigma_3$ = 57.5\n  \n\n\nKalman Filter Dynamics Test\n\nKalman Filter PD Kp = .12 | Kd = 60\n\nKalman Filter PD Control\nLab 8: Stunts\nKey Takeaways:\n\nDesigned flip stunt triggered via Bluetooth (CMD.STUNT), parameterized by wall distance for flexible tuning\nUsed ToF + Kalman fusion to track distance in real time during stunt execution\nTuned state-space A/B matrices to improve distance predictions; still noted velocity underestimation in KF\nAchieved consistent flips on mat placed 300 mm from wall; best trials completed in about 2.3 s\nCorrected drift with motor scaling factors (0.95 forward, 0.90 reverse) to keep trajectory straight\nExplored added front mass for nose-dive, but found battery charge level had greater effect on success\n\n\nFlip Trial 3 | Time: 2.30s\nLab 9: Mapping\nKey Takeaways:\n\nImplemented on-axis spin using IMU DMP yaw control with PID, turning in 12¬∞ steps for 30 total increments\nCollected about 2780 ToF samples per rotation; achieved ~1.5 in average positional error due to wheel drift/slip\nVerified minimal overshoot at slow spin speeds; tradeoff between accuracy and memory usage\nConverted raw ToF readings into global coordinates using homogeneous transformation matrices\nBuilt full-room ToF map; noise caused arcs and spurious lines, but overall map aligned closely with ground truth\nEstimated walls from ToF scans and overlaid them with the known map for validation\n\n\n360¬∞ Data Collection Scan\n\nMapping Scans\n\n\n  \n    \n    ToF Arena Map with Estimated Lines and True Map\n  \n  \n    \n    ToF Arena Map with Estimated Lines and True Map\n  \n\nLab 10: Grid Localization using Bayes Filter\nKey Takeaways:\n\nImplemented Bayes Filter in Python to probabilistically track robot state (x, y, Œ∏) in a discretized 3D grid\nBuilt odometry motion model: initial rotation, translation, final rotation; incorporated Gaussian noise\nDeveloped prediction step to propagate belief via motion model; optimized by skipping negligible states\nCreated sensor model using ToF likelihoods; updated belief grid via Bayesian inference\nSimulation showed odometry drifted, but Bayes Filter belief (blue) aligned closely with ground truth (green)\nPerformed best near walls since shorter ToF distances produced more accurate sensor updates\n\n\nBayes Simulation\nLab 11: Localization on the Real Robot\nKey Takeaways:\n\nImplemented update step on robot: performed spins, collected 36 ToF readings at 10¬∞ intervals, and sent data over BLE\nEnsured accuracy by pausing 500 ms at each angle before capturing ToF\nResults: localized robot within ~8 in of true pose; ToF underestimation shifted beliefs closer to walls\nAdjusted ToF mounting angle and reduced sensor noise parameter (sigma = 0.05) for improved reliability\nDemonstrated successful belief updates at multiple coordinates; belief (blue) tracked near ground truth (green)\n\n\nLocalization Simulation - Belief (blue), Ground Truth (green)\nLab 12: Path Planning and Final Project\nKey Takeaways:\n\nCombined all subsystems: waypoint navigation, PID orientation/linear control, Kalman ToF filtering, and Bayes localization\nDefined waypoint list with localization flags for selective belief updates along path\nOrientation PID: computed heading with atan2, rotated using DMP-based control with cutoff timer\nLinear PID: calculated target distance via ToF and belief position; advanced to waypoint\nRan localization scans at chosen waypoints using SPIN case (Lab 11 method)\nEarly runs showed overshoot and derivative blow-up; final run achieved smooth autonomous navigation through all waypoints\nDemonstrated complete system integration: perception, control, and planning working reliably in the real arena\n\n\nNavigation Plan\n\nFinal Run","path":null},{"url":"https://correial.github.io/Portfolio/cornell-nexus/","title":"Cornell Nexus","description":null,"body":"Cornell Nexus is a Cornell Engineering Project team currently working on a fully autonamous beach rover to address environmental concerns associated with microplastic pollution. Since joining my Freshman year, I have the opportunity to work on the filtration and drivetrain projects and now lead the fourteen-member mechanical team as Subteam Lead! Here are a few highlights that I have worked on and helped supervise during my time on the team. I will be updating the website with updates on my senior design project next semester Fall 2025!\nDrivetrain\nFiltration\n","path":null},{"url":"https://correial.github.io/Portfolio/frc-robotics/","title":"Horace Mann FRC High School Robotics Team","description":null,"body":"The FIRST Robotics Competition (FRC) is a rigorous international high school engineering program where teams design, build, and program large-scale robots to complete complex game challenges under strict time, budget, and technical constraints. As Team Captain during my senior year (2022), I was honored to lead my high school FRC robotics team (team 5806) to its first-ever NYC Regional Championship victory, which consequently secured the team‚Äôs first-ever qualification for the World Championships in Houston, TX. Below I expand on our design and results for the 2022 Game, Rapid React, sponsored by The Boeing Company.\nDesign Goals\n\nActive intake system designed to intake and store two balls (~9‚Äú in diameter) at a time until released\nShooting the balls with roughly 80% accuracy into 9 ft vertical hoop (4ft in diameter) while simultaneously traversing the field\nCapable of climbing 6 ft into the air via the climb structure and suspending for ~2 minutes\n\nRobot CAD Design\nPrior to building our robot, I helped lead the charge on designing our robot in CAD for more streamlined component fabrication and integration. Below are a few angles of the Fusion 360 Robot CAD\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n\nKey Integration Elements\nBelow are a few key personal contributions that contributed to our final product:\n\nFacilited inclusive design sessions and led comprehensive design reviews\nIntegrated NEO brushless motors and belt systems for shooter, intake, and drivetrain (tank drive used for more stable and powerful robot)\nCollaborated with electrical sub-team to securely mount all motors and electrical components such as LimeLight sensor for vision\nHelped complete pneumatic piston geometry calculations for climb arms, ultimately accomplished via on-board air compressor\nOperated CNC Mill alongside team lathe, band-saw, belt sander, and other power tools to machine custom parts from CAD and CAM files\n\n\n  \n    \n      \n    \n    End Game Climb (Team 5806)\n  \n  \n    \n      \n    \n    Shooter Flywheel Mechanism\n  \n\nResults\nFirst in school history‚Ä¶\n\n2022 NYC Regional Champion\nWorld Championship Qualifier (Houston, TX)\n\n","path":null},{"url":"https://correial.github.io/Portfolio/custom-automated-tensile-tester/","title":"Automated Tensile/Compression Tester","description":null,"body":"During high school Senior summer and school year I completed a virtual internship with startup Drake Labs &amp; strategic partner Orbital Composites. As part of my internship and Senior Thesis for the Horace Mann Science Reserach Program, I indepenetly designed, developed, machined, and programed a custom automated tensile tester to quantify deformation in Continous Carbon Fiber (CCF) Drake Labs LORE 3D Printed bike shoe.\nSummary\n\nDesigned and completely in house manufactured a custom automated tensile and compression tester with the goal of quantifying the integrity of a 3D printed continuous carbon fiber bike shoe\n1/4in steel stock slabs were machined to provide clearance for metal struts. Struts were welded to top slab with bottom was free to glide vertically for a variety of mounting heights.\nMain electrical components were a raspberry pie, a ‚Äúmain circuit‚Äù to control the actuator (discussed in paper), a 100kg load cell, and a  1320 lb linear actuator, and a safety enclosure to mount all components\nProgrammed scripts to control linear actuator and execute actions via feedback from load cell\nDocumented work by writing a formal research paper and creating poster for the yearly Science Research Fair (both at the bottom of page)\n\n\n  \n  \n    \n    Tensile Tester Custom Structure\n  \n  \n  \n\n  \n\nResults\n\nSuccessful in applying a tensile or compressive load to the shoe until target load is met\nNext steps: add a camera for image processing to quantify deformation\n\nScience Research Paper and Presentation\n\n\n","path":null}]