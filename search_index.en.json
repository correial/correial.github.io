[{"url":"https://correial.github.io/","title":"About Me","description":null,"body":"\n  Lucca Correia\n  \n    \n      \n    \n  \n  \n    \n      \n    \n  \n\n\n\n\n\n \nJunior at Cornell University studying Mechanical Engineering with a focus in Robotics\nHere on campus I am on the Cornell Nexus Project Team as well as the Cornell United Soccer Club Team. I will be updating my site through the semester to reflect my progress in Fast Robots MAE4190/ECE4160.\n\n","path":null},{"url":"https://correial.github.io/docs/","title":"Empty for now","description":null,"body":"\n","path":null},{"url":"https://correial.github.io/nexus/","title":"Empty for now","description":null,"body":"","path":null},{"url":"https://correial.github.io/Fast Robots/","title":"MAE 4190 Fast Robots Labs","description":null,"body":"","path":null},{"url":"https://correial.github.io/Fast Robots/lab-1/","title":"Lab 1: Artemis Setup and Communication","description":null,"body":"Lab 1a\nDuring section 1a of the lab I installed the Arduino IDE and established a wired connection to communicate with the Artemis Nano. To connect I had to select the correct board and port in the Arduino IDE. Then, to test the connection and explore the Arduino environment I completed the following assigned example sketches in the Arduino IDE:\n\nBasics_blink\nApollo3_serial\nApollo3_analogRead\nPDM_microphoneOutput\n\nBlink\nYou can see the Artemis board flash a bright blue led\n\nBlink test video\nSerial\nHere we can see the Artemis recieves the string and echos it back\n\nSerial output test\nanalogRead Temperature Sensor\n\nTemperature sensor test\nMicrophone Output\nFrom the video you can see the Artemis microphone successfully picking up the difference in sounds in the serial monitor\n\nMicrphone output test\nLab 1b\nCodebase and BLE\nBluetooth (specifically Bluetooth LE) at a high level is used to establish a connection between my computer and the Artemis:\n\n\nBluetooth LE radio acts like a community bulletin board where Computers (community members) can connect to read the board. If the radio is a bulletin board we call that a peripheral device (the Artemis in this case) and it is responsible for posting data. If the radio is a reader (central device) it reads from any of the bulletin boards. Essentially, central devices view the services, get the data, then move on, all within a few milliseconds allowing multiple central devices can get data from one peripheral.\n\n\nServices are identified by unique numbers known as UUIDs. The ability to define services and characteristics depends on the radio you’re using and its firmware. Bluetooth LE peripherals will provide services, which in turn provide characteristics.\n\n\nThere are four things that a central device can do with a characteristic: Read, Write, Indicate, and Notify\n\n\nThe codebase is collection of source code files that make up our system. Some important components:\n\n\nThe Artemis’ unique UUID and Mac address allow for undisrupted communication and transmission of BLExCharacteristics\n\n\nble_arduino.ino is the code running on the Artemis, edited in the Arduino IDE\n\n\nEString is used when transmitting strings from the Artemis to your computer\n\n\nRobotCommand.h is used when handling a robot command that the Artemis receives and is of the string format &lt;cmd_type&gt;:&lt;value1&gt; &lt;value2&gt;|&lt;value3&gt;|…\n\n\nDemo.ipynb is where you find the python code sending commands to the Artemis\n\n\nSome relevant functions used to communicate between the computer and Artemis:\n\nsend_command(cmd_type, data) to send a command\nble.connect() and ble.disconnect to connect with the Artemis\nreceive_string(uuid) to recieve a string from our board\nstart_notify(uuid, notification_handler) to activate the notification handler\nble.bytearray_to_string(byteArray) to convert recieved data into string\n\n\n\nConfigurations and Setup\n\n\nI started with installing venv: python3 -m pip install --user virtualenv\n\n\nI created the “FastRobots_ble” virtual environment inside my project directory: python3 -m venv FastRobots_ble\n\n\nI activated the virtual environment: source FastRobots_ble/bin/activate\n\n\nI downloaded the provided ble_robot_1.2 codebase into my project directory\n\n\nIt is now time to start the Jupyter server: jupyter lab\n\n\nUpdated the Artemis MAC Address on the Computer. Run the ble_arduino.ino file in the Arduino IDE and check the serial monitor the MAC address:\n\n\n\nMAC Address\n\nGenerate new UUID: run from uuid import uuid4 and uuid4(). Input the generated UUID into the #define BLE_UUID_TEST_SERVICE line in ble_arduino.ino and into the ble_service: line in connections.yaml\n\n\nconnections.yaml\n\nble_arduino.ino\n\nConnect to the Artemis Nano via BLE\n\n\n\nSuccessful BLE Connection\nTask 1\nI sent a string value from my computer to the Artemis board using the  ECHO command and the computer recieved and printed the augmented string\nArduino Code:\n\nJupyter Lab Code:\n\n\n\nECHO Output\nTask 2\nI sent three floats to the Artemis board using the SEND_THREE_FLOATS command and extracted the three floats in the Arduino sketch\nArduino Code:\n\nJupyter Lab Code:\n\n\nSEND_THREE_FLOATS Output\nTask 3\nI added a GET_TIME_MILLIS which makes the robot reply write a string to the string characteristic. GET_TIME_MILLIS had to be added to the cmd_types.py file. GET_TIME_MILLIS had to be added to cmd_types.py to run. Note that the output looks the same as in task 4.\n\nTask 4\nI setup a notification_handler function to receive the string value from the Artemis board and, in the callback function, extract the time from the string.\n\n\n\n\nNotification Handler Output\nTask 5\nI made a twenty-five step loop that gets the current time in milliseconds using the GET_TIME_MILLIS function to then be processed by notification_handler(). From my output shown below you can see that there was an average 33.5 ms gap between the prints. This translates to 29.85 message transmissions per second. With each message being 9 bytes (1 char per each string sent), this results an effective data transfer rate of 269 bytes per second for this method.\n\n\nGET_TIME_MILLIS Loop Output\nTask 6\nI created a command SEND_TIME_DATA that loops though to add generated time steps via the millis() function and then stores them in an array. Then, in SEND_TIME_DATA I loop through the array and send each data point as a string to my laptop to be processed. SEND_TIME_DATA had to be added to the cmd_types.py file. Note that millisArray[i] is defined as a global array.\nArduino Code\n\nJupyter Code:\n\n\nSEND_TIME_DATA Output\nTask 7\nI created a second array to store fahrenheit temperature readings with the same length as the one used in task 6. Each index in both global arrays (millisArray[] and tempArray[]) correspond to each other. The command GET_TEMP_READINGS loops through both arrays concurrently and sends each temperature reading with a time stamp. The notification handler parses these strings and populates the data into two lists. Note that GET_TEMP_READINGS had to be added to the cmd_types.py file.\n\n\nTemp and Time Output\nTask 8\nRate wise, it is clear from the time steps in tasks 5 vs. 6 that method one is considerably slower at recording data than method two. This is because method one has to wait until the Artemis sends data to the computer after every round of collection before recording again. Instead, the second method can effectively record data as fast as its slowest sensor, thus producing data that may be more accurate but at the expense of a delayed reception on the client’s end. This could result in a slower response time from the robot and thus is less applicable if the robot needs to make time-sensitive decisions from sensor data. For an open-loop test where we do not care as much about real-time feedback, method two may be more useful as the faster data recording would provide higher resolution.\nIn order to determine how quickly the second method records data, I had to increase the number of loop iterations to 100 in order to see a difference in time steps. The first element is T: 104510ms and the 100th is T: 104512ms which translates to data being recorded every 0.02ms on average (considerably faster than the 33.5 ms gap in task 5).\nThe millis() int variable and getTempDegF() int variable are both stored as ints of 4 bytes each for a total of 8 bytes. As printed by the Arduino IDE output, global variables use 30648 bytes. If the Artemis board has 384 kB of RAM, then 353,352 bytes remain allowing us to store a total of 353,352 bytes/8 bytes = 44,169 data points without running out of memory.\nDiscussion and Conclusion (Lab 1A &amp; 1B)\n\nLearned about what functions are responsible for communication between my computer and Artemis and how the commands (ECHO, GET_TIME_MILLIS, etc.) are passed in via RobotCommand.h\nAt first I was confused about the relationship between different data types and their byte size. However, the later questions in the lab made it clear how ints vs. strings require different number of bytes as well as how Estring char are used to send those types to the computer\nThe largest problem I faced was understanding the parameters needed for the notification handler!\n\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Daria’s site for code debugging and specific help with SEND_TIME_DATA and GET_TEMP_READINGS. ChatGPT was used for Lab 1B code debugging and website formatting/development.\n","path":null},{"url":"https://correial.github.io/Fast Robots/lab-2/","title":"Lab 2: IMU","description":null,"body":"IMU Setup\nAD0_VAL &amp; Initial Data Observations\nThe AD0_VAL represents the last bit of the I2C address. In our case, 1 is set as the default and that shouldn’t be changed unless the ADR on the board is closed via solder and then should be set to 0.\nAfter testing with the example code as well as the lecture 4 code, it appears that the accelerometer and gyroscope data print as expected. Three axis are printed for both sensor as well as the corresponding unit (mg for acceleration and DPF for the gyroscope). As discussed in lecture, in the data you can see accelerations and rotations being tracked but not absolute position; changes in the printed values only occur with movement. Additionally, you can see that the changing values are dependent on the axis being rotated about and the sensor being observed. When rotating around the z-axis you can see that the accelerometer data does not change, however the gyroscope does. When accelerating the board along the x-axis you can see a change in value for the accelerometer x-axis but not the gyroscope.\n\nArtemis and IMU Connection with BLUE LED Indicator\nAccelerometer\nAccelerometer Data to Pitch and Roll Conversion\n\n\nVideo of IMU Testing - full screen to reduce blur\n\n    \n        \n        0°\n    \n    \n        \n        Pitch @ -90°\n    \n    \n        \n        Pitch @ 90°\n    \n    \n        \n        Roll @ -90°\n    \n    \n        \n        Roll @ 90°\n    \n\nAs you can see from the frozen frames, the accelerometer is very accurate with vary little variation in angle from the expected value. As a result I do not think it is nessesary to do a two-point calibration.\nData Collection and Plotting Code\nThe following code was used to collect the data in arrays and then use Juypter to pipe the data from the Artemis into a CSV file and graph. Note that as I added more arrays to store more data (LPF, Gyro, Complementary Filter) I simply added more columns to the csv via the notification handler. The graphs will be shown later in the lab for analysis.\nArtemis Aruino Code:\n\nJupyter Code:\n\nFourier Transform and Low Pass Filter Plotting\nThe raw data shows some noise in the higher frequencies however it is fairly negligable. This is due to the fact that the IMU has a low pass filter implemented already. Regardless, I will add a low pass filter\nWhen collecting dat in the proximity of the running car, the most noise appeared to be in the range of 0 Hz and 5 Hz; I will make the cutoff at 5 Hz. The lowpass filter effects the output by limiting faster frequencies (which we are defining as noise) from being shown in the data. If the frequency chosen is too small, you will still have unwanted noise in the smaller frequency range. However, if you pick too high of a cutoff frequency you run the risk of ignoring data points that may actually be important and a correct reflection of the robot’s movement (maybe a sharp turn on a flip).\nIn order to apply a low pass filter I had to calculate my alpha value as 0.0876 using following equations:\n$$\\alpha = \\frac{T}{T + RC}$$\n$$ f_c = \\frac{1}{2\\pi RC} $$\n\nT = sampling rate\n$f_c$ = cutoff frequency\n\n\nRaw and Fourier Transform Data with Low Pass Filter - Car in Proximity\n \n\nRaw and Fourier Transform Data with Low Pass Filter - Hand Osscilations\n \n\nRaw and Fourier Transform Data with Low Pass Filter - Hitting Table\nYou can see that the low pass filter is successful in reducing unwanted noise in the accelerometer data. This is especially clear in the final graphic (Raw and Fourier Transform Data with Low Pass Filter - Hand Osscilations) where the LPF works to ignore the spikes in magnitude that comes from hitting the table.\nGyroscope\nEquations to compute pitch, roll, and yaw angles from the gyroscope:\n\nGyroscope vs. Accelerometer Data\nWhen first collecting the gyroscope readings I noticed that the data did not match the accelerometer data. I realized that due to the default axis of the gyroscope, the pitch and roll for the gyroscope really corresponded to the roll and pitch of the accelerometer respectively (and make the pitch negative).\n\nInitial Gyro vs. Accelerometer Readings (Flipping Needed) \nAfter making those changes, I noticed that there was still drift from the gyroscope over time, likely due from integrating the error in each step. However, I did find it interesting that the gyroscop provided cleaner and smoother data during quick direction changed (going from -90 to 90 degrees and back). Thus while the gyroscope alone may not be highly accurate, it is still stable.\n\nRaw Gyro Data vs. Accelerometer Readings \nTo observe the effects of changing the sampling rate, I added delays in my case GET_ACC_READINGS command code FOR loop to slow down the data collection. I noticed that a delay of 10 ms added some choppiness to the plotting without a significant increase it collection time. However, adding a 100 ms delay significantly increased the data collection time as well as the choppiness in the plot. The gyroscope, which I found was especially good at tracking quick changes of direction smoothly is now not nearly as clear. Additionally, you can see the plot jumping around for smoother IMU movements as the gaps between time intervals is increased.\nComplementary Filter Implementation\nThe following code was used to imlpement my complementary filter:\n\n\nComplementary Filter Gyro vs. Low Pass Filter Accelerometer\nFrom the results you can that with an alpha value of 0.0876 the combined measurements from the accelerometer and gyroscope significantly increases stability (which comes from the gyroscope) and accuracy (from the low pass filter accelerometer).\nSampling Data\nSpeed Up\nI took a few measures to speed up the execution time for my main loop:\n\nRemoved the part in my code where I wait for IMU data to be ready (for example checking(myICM.dataReady()) to move through the command loop. Instead I check if data is ready in the main loop and if it is I call the function collectIMU() to compute the pitch, roll and yaw. After computing I add them to their respective arrays and iterate through those arrays with a different command (that does not affect the resolution as data is already collected).\nRemoved debugging print statments in my command to get IMU data\nI use flags to start/stop data recording\n\nWhile my IMU was able to sample new values farily quickly (~ 350 Hz) after cleaning up my code, the main loop runs significantly faster than my IMU produces new data. This is evident when comparing the IMU_Count variable (which only runs when data is collected) to the Total_Loops (which counts the number of times cycled through the main). The Total_Loops is larger on the magnitude of 10-100x which means that the IMU is the holdup.\nCode of main loop function:\n\ncollectIMU() function:\n\nJupyter code to start/stop data collection via setting a global start variable to 1 or 0 within the START_DATA_COLLECTION and START_DATA_COLLECTION commands:\n\nThe old case GET_ACC_READINGS command was called in Jupyter after stopping data collection to then re-popoulate the csv file with new values.\n\nCSV proving population of time-stamped IMU data in arrays\nData Storage\nI decided that it would be best to have seperate arrays for storing accelerometer and gyroscope data rather than one large one. This was partially because I decided that it would be easier to organize and parse through the data using different arrays to compartmentalize the data before sending them over bluetooth. I also found it easier to create a CSV from the seperate arrays in Jupyter.\nEach of these arrays contain floats as the gyroscope and acceleration naturally output decimal values. With a double data type being twice the size of a float (64 vs 32 bits), I decided that a float was the best data type for these sensor arrays.\nI have a total of 10 floats arrays for a total of 40 bytes at a time:\n\n1 for time\n2 for accelerometer roll and pitch\n2 for LPF roll and pitch\n3 for gyroscope roll, pitch, and yaw\n2 for complementary filter data\n\nIn lab 1b global variables use 30,648 bytes. This lab we added the above arrays to send IMU data. If the Artemis board has 384 kB of RAM, then 353,352 bytes of dynamic memor remain which allow us to store 353,352/40 = 8833 data points. With an average step time of 2.86 ms (shown below) we get a sample rate of 349.65 Hz. This corresponds to 25.26 seconds of IMU data collection.\n5 Seconds of IMU Data\n\nProving 5 Seconds of IMU Data\nI used one of my CSV files as an example of collecting at least 5 seconds of data and sending it over bluetooth. To do this I took the difference between the first time stamp and the last time stamp in my proximityFinal.csv file:\n\nRC Stunts\n\nStunt 1\n\nStunt 2\nThe car is quick at direction changing and accelerating. When spinning it is able to hold its position on the ground without drifting much. Note that the car’s speed can not be changed while moving, it can only stop and change directions.\nCollaboration\nI collaborated extensively on this project with Jack Long and Trevor Dales. I referenced Daria’s site for code debugging in my complementary filter as well as visually understanding how to effectively display my plots. ChatGPT was heavily used to write plotting code for the Raw, FFT and LPF data. It also helped me write my FFT function as the provided link had some syntax error and missing pictures.\n","path":null}]